# QLoRA: Efficient Finetuning of Quantized LLMs

https://arxiv.org/abs/2305.14314

We present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters~(LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information theoretically optimal for normally distributed weights (b) double quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) paged optimziers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to ChatGPT. We release all of our models and code, including CUDA kernels for 4-bit training.


我们提出了QLoRA，这是一种有效的微调方法，它可以减少内存使用，足以在单个48GB GPU上微调65B参数模型，同时保持完整的16位微调任务性能。QLoRA通过冻结的4位量化预训练语言模型将梯度反向传播到低秩适配器~（LoRA）中。我们的最佳模型系列，我们将其命名为Guanaco，在维库纳基准测试中优于之前公开发布的所有模型，达到ChatGPT的99.3%的性能水平，同时只需要在单个GPU上进行24小时的微调。QLoRA引入了一系列创新，以在不牺牲性能的情况下节省内存：（a）4位NormalFloat（NF4），这是一种新的数据类型，理论上对正态分布权重是最优的信息；（b）通过量化量化常数来减少平均内存占用；（c）分页优化器来管理内存峰值。我们使用QLoRA对1000多个模型进行了微调，对8个指令数据集、多种模型类型（LLaMA、T5）和无法通过定期微调运行的模型规模（例如33B和65B参数模型）的指令跟随和聊天机器人性能进行了详细分析。我们的研究结果表明，即使使用比以前的SoTA更小的模型，QLoRA在小的高质量数据集上的微调也会带来最先进的结果。我们基于人工和GPT-4评估对聊天机器人的性能进行了详细分析，表明GPT-4的评估是人工评估的一种廉价合理的替代方案。此外，我们发现，目前的聊天机器人基准测试不足以准确评估聊天机器人的性能水平。一项柠檬采摘的分析证明了Guanaco与ChatGPT相比的失败之处。我们发布了所有的模型和代码，包括用于4位训练的CUDA内核。