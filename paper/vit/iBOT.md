# iBOT: Image BERT Pre-Training with Online Tokenizer
2021.11.15 https://arxiv.org/abs/2111.07832

## Abstract 
The success of language Transformers is primarily attributed to the pretext task of masked language modeling (MLM), where texts are first tokenized into semantically meaningful pieces. In this work, we study masked image modeling (MIM) and indicate the advantages and challenges of using a semantically meaningful visual tokenizer. We present a self-supervised framework iBOT that can perform masked prediction with an online tokenizer. Specifically, we perform self-distillation on masked patch tokens and take the teacher network as the online tokenizer, along with self-distillation on the class token to acquire visual semantics. The online tokenizer is jointly learnable with the MIM objective and dispenses with a multi-stage training pipeline where the tokenizer needs to be pre-trained beforehand. We show the prominence of iBOT by achieving an 82.3% linear probing accuracy and an 87.8% fine-tuning accuracy evaluated on ImageNet-1K. Beyond the state-of-the-art image classification results, we underline emerging local semantic patterns, which helps the models to obtain strong robustness against common corruptions and achieve leading results on dense downstream tasks, eg., object detection, instance segmentation, and semantic segmentation.

语言Transformers的成功主要归功于遮蔽语言建模(MLM)这一借口任务，即文本首先被标记化为语义上有意义的片段。在这项工作中，我们研究了掩码图像建模(MIM)，并指出了使用语义上有意义的视觉标记器的优势和挑战。我们提出了一个自监督框架iBOT，它可以使用在线标记器执行掩码预测。具体来说，我们对掩码分块令牌执行自蒸馏，并将教师网络作为在线令牌化器，同时对类令牌进行自蒸馏以获取视觉语义。在线令牌化器可与MIM目标联合学习，并省去了需要预先对令牌化器进行预训练的多级训练管道。我们通过在ImageNet-1K上实现82.3%的线性探测精度和87.8%的微调精度，展示了iBOT的突出性。除了最先进的图像分类结果，我们强调了新兴的局部语义模式，这有助于模型获得对常见损坏的强大稳健性，并在密集型下游任务(例如，对象检测、实例分割和语义分割)上取得领先的结果。
