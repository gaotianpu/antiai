# chatGPT

## 一、发展展望
1. 回顾历史：平台(闭源|开源)(pc:windows/mac/linux,mobile:ios/android) -> app开发者 -> 应用者 。 一层层的扩散，3年平台繁荣，5年app繁荣期，后续就是应用者们发挥想象力的时候。对AI开发者来说，珍惜这3~5年的机会 ~ (纠结：这波AI是像pc/mobile这样级别的机会呢，还是像搜索引擎、电商、短视频这种app级的机会？)

## 二、技术原理
1. [Transfomers](./nlp/transformer.md), 基于自注意力机制
2. [GPT-1](./nlp/gpt.md)  自回归生成式模型，多任务统一的微调
    * [GPT-2](./nlp/gpt_2.md) 全网规模的大数据集,BPE输入表示,pre-LN,初始化策略， 零样本
    * [GPT-3](./nlp/gpt_3.md) 2020.5.28 使用交替的密集和局部带状稀疏注意模式， 提示学习
3. [InstructGPT](./nlp/gpt_InstructGPT.md)  2022.3.4
    * [Learning to summarize from human feedback](./nlp/summarize_HF.md) 2020.9.2 (引入了基于人类反馈的强化学习)
    * [WebGPT](./nlp/gpt_WebGPT.md) 2021.12
    * [Proximal policy optimization algorithms](./RL/PPO.md) 2017.7 RHLF的强化学习算法

## 三、开源项目
* [Google研究员整理的开源进展](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9807727802367385070%22%7D&n_type=-1&p_from=-1)， 里面提到的几个重要开源项目
    * 开源的语言大模型：Meta的LLaMA -> Alpaca
    * 插件式微调：微软的LoRA -> PEFT， 低秩分解（low-rank factorizations）, 将更新矩阵的大小减少了几千倍, 实现可堆叠微调。
    * 小型高质量数据集-ShareGPT，通过在小而高度精选后的数据集上训练来节省时间：Data Doesn't Do What You Think
    * 充分利用开源的大模型权重，不需要再往基础大模型投入过大精力；在开源大模型基础上，基于LoRA做定制微调；
* https://mp.weixin.qq.com/s/3bV7hJGbP6m8_5Vspj9w8A
    * 开源项目梳理，提到不少中文项目
    
### 大语言模型
1. 2023.2.24 [Meta's LLaMA](https://github.com/facebookresearch/llama)
    * https://huggingface.co/docs/transformers/main/model_doc/llama
2. 2023.3.13 [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca)
3. 2023.3.19 [Vicuna](https://github.com/lm-sys/FastChat) 
4. Koala: A Dialogue Model for Acadeic Research 
5. [Dromedary](https://github.com/IBM/Dromedary)  SELF-ALIGN
6. Anthropic ？
~ 

Pythia：OpenAssistant和Dolly

1. https://huggingface.co/gpt2
1. https://github.com/Vision-CAIR/MiniGPT-4
1. https://github.com/nomic-ai/gpt4all



### chat
1. https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat #源码很好，值得花时间阅读。
2. [DeepSpeed Chat](https://github.com/microsoft/DeepSpeed)


[Data Doesn't Do What You Think](#) 使用合成方法构建（例如，过滤现有模型中的最佳响应）并从其他项目中获取
ShareGPT

 PyTorch FSDP ？


指令调整（instruction tuning）、量化（quantization）、质量改进（quality improvements）、人类评估（human evals）、多模态、RLHF.

github.com/eugeneyan/open-llms 



图像合成的 Latent Diffusion,LLM 的 Chinchilla

* 微软的 [DeepSpeed Chat](https://github.com/microsoft/DeepSpeed)，开源chatGPT训练方案，模型算法这块以后不会是竞争壁垒，数据和算力是壁垒，AI会和PC/手机产业一样：商业闭源/开源系统 + 第三方生态。
    * 对齐算法RAFT, https://arxiv.org/abs/2304.06767，https://github.com/OptimalScale/LMFlow。PPO是否是必须的？足够大的SFT是否就能很好？
    * 数据集：https://mp.weixin.qq.com/s/WMqJqtjG36ko7m-B4Gv4_A

## 三、应用
1. prompt
2. plugin




## 二、数据很重要
1. 预训练大模型，强调全网爬虫能力。
2. prompt/模型输出->质量得分，需大量人工标注。先有数据哪些可用的？例如，搜索引擎的query-答案等；问答站点，人工构造的prompt-回答对等
3. ShareGPT.com
4. self-Instruct

## 三、业界
1. OpenAI 的chatGPT (类似Windows/iOS)， 商业闭源 + 开放API + 第三方生态插件
    * 2~3年的窗口期，国内头部互联网企业、创业公司、资本进入，谁能先胜出，数据飞轮就能先启动；
2. 微软 的 deepspeed-chat (类似Linux/android), 开源 + 高度定制化
    * 垂直、私密领域的部署？
3. 生态插件
    * 编程、办公、创意、影视制作
    * CAD? 
4. 对话式交互比较初级(pc早起的dos界面)，图形交互(GUI)是终极(类似segment anything).



## 思考
1. chatGPT为什么出自OpenAI,而不是google,meta等？
2. 超越语言层次之上的逻辑推理能力是如何获得？
3. chatGPT对于新闻事实类的回答，需连网，从doc中提取事实观点等；



3. prompt-based learning(基于提示的学习,通过编写提示模板，下游任务向预训练模型对齐)  
5. 工程实现: 训练数据规模、算法参数规模、训练/应用时的算力消耗规模
6. 统一大模型迈向通用智能，几个关键障碍似乎已经扫除，后面可能还会还有更劲爆的AI应用犹如雨后春笋般冒出
    * 统一的输入输出：图像、音频、文字等，模型可以一股脑全接收并做出正确的回应。 输入、输出格式？
    * 元学习：即使某些任务并未显示训练，经少量提示就能明白用户意图
    * 人机交互中，引入普通人类反馈机制迭代模型能力
    * 推理部署：能够根据任务的复杂度，智能调节算力消耗

## 应用场景
1. 基于统一大模型，让模型学习物理常识：通过摄像头观察真实场景的变化，根据一段时间的视频信息预测接下来几秒钟各种物体的运动轨迹。如此会学习到一些物理常识，物体在阳光下的影子会从西向东走，杯子掉了会落地，抛出的篮球会做抛物线运动，如果遇到红灯汽车会减速等等，并把这些总结到的物理现象用人类语言表述出来。
对于预测结果，一方面，可以和实际的预测轨迹做比对，纠正预测错误的部分，另一方面，引入用户反馈机制，让人用文字形式告诉模型，哪个物体运动轨迹预测错误了,使用强化学习迭代模型的预测结果，让物理规律和人类语言建立关系。




## 技术原理细节
1. 强化学习如何对待用户反馈？对于用户的纠错，如何判断是真的错了，还是恶意误导？

## chatGPT能干什么
1. [写代码，程序员沦为高级数据标注师](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10103958109212429965%22%7D&n_type=-1&p_from=-1)
2. 医疗问诊，

## 与AI相处
1. 未来普通人应该如何与AI相处，


## 国内的参赛选手


## 可能的影响
0. 人机交互革命？
PC：鼠标+键盘+屏幕(CRT->液晶);  手机：触屏+虚拟键盘 -> 语音输入, 更多的传感器引入(地理位置，摄像头); chatGPT: 对话方式，目前的键盘输入为主流，未来会是语音输入为主流，纯文本的回复，结合排版软件图文并茂的文档格式; 
对于人类来说，如何使用这类工具，博闻广见，死记硬背不再是优势？ 和chatGPT对话，获得灵感，解决问题。
1. 流量入口：包括PC、手机、座舱、电视、音箱、门铃等任何能想到的智能交互设备，分成问题解决后，各大硬件厂商会迅速跟进，会截流很多浏览器、搜索引擎的流量; 
(思考：万物互联的背景下，智能交互设备无需自带屏幕，可以选择投屏到别的屏幕设备上。) 获取信息的三种方式：搜索、推荐、聊天，以聊天的形式改变搜索行为？
2. 数据版权问题：由于chatgpt会给出用户最需要的内容，
* 从整个海量数据中抽取、打散、重新生成的内容; 内容原创者想要获得版权利益，举证困难，法律空白地带，chatgpt的基本盘; 
* 某个内容(文字、音频、视频)的满足片段; chatgpt需要跟内容创作者达成分成协议。
* 第三方服务，传统的酒店、票务、电商的订单接口，在某个垂直领域做的很好的AI服务等;  这个会是互利行为，容易达成合作共识; 
* 某些垂类行业知识，chatgpt会有会话历史挖掘机制，将满足不好的回复抽取出来，可能需要高级标注工给出正确答案，满足大模型的迭代，高级知识分子沦为chatgpt打工人。
* 输出格式美化，office/pdf/网页/视频等; 这些是软件厂商的接入机会; 
* 智能客服：电商售前/售后、医疗问诊 90%问题能正常回答，如果ai回答不满意，人工客服介入回答，可以将修正问题回馈给模型以供迭代。
3. 算力、存储等硬件需求
* 内容不断增加，大模型迭代
* 个性化回答，要求模型主要参数可以统一，针对每个用户又有差异，记录用户会话，迭代用户模型本身也需要巨量存储计算
* 窗口刚刚打开，距离窗口期关闭，可能还有2~3年的时间，各厂商可能都会跟进研发，硬件需求暴涨; 

## 生态主导者(指有能力发布chatGPT产品的企业)
1. 窗口刚刚打开，距离窗口期关闭，可能还有2~3年的时间，国内的百度(搜索)，腾讯(聊天)，字节(头条抖音)等先天优势比较明显; 阿里、美团等电商、本地生活也存在大量的应用场景; 部分手机企业或AI公司等; 资本会蜂拥而至，人力资源配置响应的也会跟进。
2. 策略算法：熟悉transformer,GPT,基于提示学习,InstructGPT的各种高级算法工程师; 
大企业的算法工程师思路调整。目前是各条业务线拿着BERT/Ernie等预训练模型，再收集不同下游任务的训练数据，产生很多个不同的最终模型; 
未来会是各业务线收集完不同下游任务的训练数据，反向适配大模型，每条业务线都有备案的测试集，模型迭代时，将每个测试集跑下结果，持平或有进步时才迭代模型，产出一个新版本; 每一个版本，要求每个分支都要合入主干。
拿代码开发距离，之前是从主干拉一个分支，在分支上改完后上线使用，分支改动不再合入主干; 现在是从主干拉分支、在分支改动、回归历史上的单元测试集，没问题后合入主干(代码+测试集都合入)。
好处，各种训练数据不浪费
问题：每条业务线的问题需要的算力不同，根据需要优化算力需求，模型蒸馏？
3. 算法蒸馏、部署等工程
4. 数据工程：大语料的清洗、存储、大模型训练
5. 数据标注：通用知识，垂类行业知识，历史会话的数据分析挖掘：识别出回答的不好的内容
6. 人机交互部分的工程：
7. 生态API开发维护
8. 硬件采购
* 以chatgpt为代表的更多大模型还将不断快速突破，算力需求可能会是在现有算力基础上的倍数增速，GPU/TPU的研发、制造企业未来不愁没订单，构成一定的投资指导原则。

### 附：有哪些方向可以完善chatgpt? from chatgpt
1. 数据增强：通过更多的数据来提高chatgpt的准确性; 
2. 模型优化：改进模型结构，提高模型的准确性; 
3. 语义理解：改进语义理解能力，更好地理解用户的意图; 
4. 语言生成：改进语言生成能力，更好地生成自然语言; 
5. 对话管理：改进对话管理能力，更好地管理复杂的对话场景; 
6. 情感分析：改进情感分析能力，更好地识别用户的情感; 
7. 内容检索：改进内容检索能力，更好地检索相关的信息; 
8. 对话策略：改进对话策略，更好地控制对话的流程; 
9. 对话记忆：改进对话记忆能力，更好地记住用户的信息; 
10. 对话维护：改进对话维护能力，更好地维护对话的连贯性。


## 生态参与者
1. 大部分人可能无法直接参与生态主导者建设获得回报，第三方生态建设可以考虑; 
1. 流量入口型企业：手机厂商，各种智能设备厂商; 样本会主动找上门求合作流量引入; 
2. 智能交互设备中用于意图理解的边缘智能计算芯片; (接受语音输入，主要通过语音答复，必要时可连接屏幕，将可视答案投屏)。
3. 人机交互主体是对话方式，传统上的UI创新机会不大?
* 输入：对于多模交互的意图理解，主体应该不能全都干完了？ 第三方干完了逐渐被主体吸纳了？
* 输出：内容输出形式，也可以借助office/网页形式/pdf/代码形式等给出更精致的排版; 
4. 自动下单？调用酒店、票务等服务接口，自动完成下单、支付、日程提醒等; 

## 应用场景
### 酒店预订系统接入
0. 给我订一张北京西站的酒店，200块钱左右的; 
1. 酒店位置、房间等基础信息提交
2. 实时价格更新
3. 搜索、排序过程，由chatgpt完成; 

### 智能客服
1. 将过往历史对话数据整理成：问题-正确回答，正样本; 问题-不正确回答，负样本，提交至chatgtp;
2. 接入api
3. 回复后其他商品的促销推荐？


## 能力测试
1. 试题扫描
1. $2^n+n^2+n$, n=1,2,3,4,5,6,7的答案给出提示，问n=20对应的是多少？
1. 多轮对话
2. 图片理解：图中有几个三角形？
