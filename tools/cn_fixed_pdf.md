## References
* Atienza, R. 2021. Vision Transformer for Fast and EfficientScene Text Recognition. arXiv preprint arXiv:2105.08582.
* Baek, J.; Kim, G.; Lee, J.; Park, S.; Han, D.; Yun, S.; Oh,S. J.; and Lee, H. 2019. What is wrong with scene text recognition model comparisons? dataset and model analysis. InProceedings of the IEEE/CVF International Conference onComputer Vision, 4715–4723.
* Baek, J.; Matsui, Y.; and Aizawa, K. 2021. What if WeOnly Use Real Datasets for Scene Text Recognition? Toward Scene Text Recognition With Fewer Labels. In Proceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition (CVPR), 3113–3122.
* Bao, H.; Dong, L.; and Wei, F. 2021. BEiT: BERT PreTraining of Image Transformers. arXiv:2106.08254.
* Bautista, D.; and Atienza, R. 2022. Scene Text Recognition with Permuted Autoregressive Sequence Models. arXivpreprint arXiv:2207.06966.
* Bhunia, A. K.; Chowdhury, P. N.; Sain, A.; and Song, Y.-Z.2021a. Towards the Unseen: Iterative Text Recognition byDistilling From Errors. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 14950–14959.
* Bhunia, A. K.; Sain, A.; Kumar, A.; Ghose, S.; Chowdhury, P. N.; and Song, Y.-Z. 2021b. Joint Visual SemanticReasoning: Multi-Stage Decoder for Text Recognition. InProceedings of the IEEE/CVF International Conference onComputer Vision (ICCV), 14940–14949.
* Bleeker, M.; and de Rijke, M. 2019. Bidirectional scenetext recognition with a single decoder. arXiv preprintarXiv:1912.03656.
* Bluche, T. 2016. Joint line segmentation and transcriptionfor end-to-end handwritten paragraph recognition. Advancesin Neural Information Processing Systems, 29: 838–846.
* Bluche, T.; and Messina, R. 2017. Gated convolutional recurrent neural networks for multilingual handwriting recognition. In 2017 14th IAPR international conference on document analysis and recognition (ICDAR), volume 1, 646–651.IEEE.
* Cai, H.; Sun, J.; and Xiong, Y. 2021. Revisiting Classification Perspective on Scene Text Recognition.
* Chowdhury, A.; and Vig, L. 2018. An efficient end-toend neural model for handwritten text recognition. arXivpreprint arXiv:1807.07965.
* Cubuk, E. D.; Zoph, B.; Shlens, J.; and Le, Q. V. 2020. Randaugment: Practical automated data augmentation with a reduced search space. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops, 702–703.
* Cui, M.; Wang, W.; Zhang, J.; and Wang, L. 2021. Representation and Correlation Enhanced Encoder-Decoder Framework for Scene Text Recognition. In Llad´os, J.; Lopresti,D.; and Uchida, S., eds., Document Analysis and Recognition – ICDAR 2021, 156–170. Cham: Springer InternationalPublishing. ISBN 978-3-030-86337-1.
* Deng, J.; Dong, W.; Socher, R.; Li, L.-J.; Li, K.; and FeiFei, L. 2009. Imagenet: A large-scale hierarchical imagedatabase. In 2009 IEEE conference on computer vision andpattern recognition, 248–255. Ieee.
* Devlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019. BERT: Pre-training of Deep Bidirectional Transformers forLanguage Understanding. arXiv:1810.04805.
* Diaz, D. H.; Qin, S.; Ingle, R.; Fujii, Y.; and Bissacco,A. 2021. Rethinking Text Line Recognition Models. arXiv:2104.07787.
* Dong, L.; Yang, N.; Wang, W.; Wei, F.; Liu, X.; Wang,Y.; Gao, J.; Zhou, M.; and Hon, H.-W. 2019. UnifiedLanguage Model Pre-training for Natural Language Understanding and Generation. arXiv:1905.03197.
* Dosovitskiy, A.; Beyer, L.; Kolesnikov, A.; Weissenborn,D.; Zhai, X.; Unterthiner, T.; Dehghani, M.; Minderer, M.;Heigold, G.; Gelly, S.; Uszkoreit, J.; and Houlsby, N. 2021. An Image is Worth 16x16 Words: Transformers for ImageRecognition at Scale. ICLR.
* Fang, S.; Xie, H.; Wang, Y.; Mao, Z.; and Zhang, Y. 2021. Read Like Humans: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition. In Proceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition (CVPR), 7098–7107.
* Gao, Y.; Chen, Y.; Wang, J.; Tang, M.; and Lu, H. 2019. Reading scene text with fully convolutional sequence modeling. Neurocomputing, 339: 161–170.
* Graves, A.; Fern´andez, S.; Gomez, F.; and Schmidhuber, J.2006. Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks. In Proceedings of the 23rd international conference on Machine learning, 369–376.
* Graves, A.; and Schmidhuber, J. 2008. Offline handwriting recognition with multidimensional recurrent neural networks. Advances in neural information processing systems,21: 545–552.
* Gupta, A.; Vedaldi, A.; and Zisserman, A. 2016. Syntheticdata for text localisation in natural images. In Proceedings ofthe IEEE conference on computer vision and pattern recognition, 2315–2324.
* Ingle, R. R.; Fujii, Y.; Deselaers, T.; Baccash, J.; and Popat,A. C. 2019. A scalable handwritten text recognition system. In 2019 International Conference on Document Analysis and Recognition (ICDAR), 17–24. IEEE.
* Jaderberg, M.; Simonyan, K.; Vedaldi, A.; and Zisserman,A. 2014. Synthetic Data and Artificial Neural Networksfor Natural Scene Text Recognition. In Workshop on DeepLearning, NIPS.
* Kang, L.; Riba, P.; Rusi˜nol, M.; Forn´es, A.; and Villegas, M. 2020. Pay attention to what you read: Nonrecurrent handwritten text-line recognition. arXiv preprintarXiv:2005.13044.
* Karatzas, D.; Gomez-Bigorda, L.; Nicolaou, A.; Ghosh, S.;Bagdanov, A.; Iwamura, M.; Matas, J.; Neumann, L.; Chandrasekhar, V. R.; Lu, S.; et al. 2015. ICDAR 2015 competition on robust reading. In ICDAR.
* Karatzas, D.; Shafait, F.; Uchida, S.; Iwamura, M.; i Bigorda, L. G.; Mestre, S. R.; Mas, J.; Mota, D. F.; Almazan,J. A.; and De Las Heras, L. P. 2013. ICDAR 2013 robustreading competition. In ICDAR.
* Krishnan, P.; and Jawahar, C. V. 2016. Generating SyntheticData for Text Recognition. arXiv:1608.04224.
* Kudo, T.; and Richardson, J. 2018. Sentencepiece: Asimple and language independent subword tokenizer anddetokenizer for neural text processing. arXiv preprintarXiv:1808.06226.
* Lee, J.; Park, S.; Baek, J.; Oh, S. J.; Kim, S.; and Lee, H.2020. On recognizing texts of arbitrary shapes with 2D selfattention. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition Workshops, 546–547.
* Liao, M.; Wan, Z.; Yao, C.; Chen, K.; and Bai, X. 2019. Real-time Scene Text Detection with Differentiable Binarization. arXiv:1911.08947.
* Litman, R.; Anschel, O.; Tsiper, S.; Litman, R.; Mazor,S.; and Manmatha, R. 2020. Scatter: selective contextattentional scene text recognizer. In Proceedings of theIEEE/CVF Conference on Computer Vision and PatternRecognition, 11962–11972.
* Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.;Levy, O.; Lewis, M.; Zettlemoyer, L.; and Stoyanov, V.2019. RoBERTa: A Robustly Optimized BERT PretrainingApproach. arXiv:1907.11692.
* Lyu, P.; Zhang, C.; Liu, S.; Qiao, M.; Xu, Y.; Wu, L.; Yao,K.; Han, J.; Ding, E.; and Wang, J. 2022. MaskOCR:Text Recognition with Masked Encoder-Decoder Pretraining. arXiv preprint arXiv:2206.00311.
* Memon, J.; Sami, M.; Khan, R. A.; and Uddin, M. 2020. Handwritten optical character recognition (OCR): A comprehensive systematic literature review (SLR). IEEE Access,8: 142642–142668.
* Michael, J.; Labahn, R.; Gr¨uning, T.; and Z¨ollner, J. 2019. Evaluating sequence-to-sequence models for handwrittentext recognition. In 2019 International Conference on Document Analysis and Recognition (ICDAR), 1286–1293. IEEE.
* Mishra, A.; Alahari, K.; and Jawahar, C. 2012. Top-downand bottom-up cues for scene text recognition. In CVPR.
* Mou, Y.; Tan, L.; Yang, H.; Chen, J.; Liu, L.; Yan, R.; andHuang, Y. 2020. Plugnet: Degradation aware scene textrecognition supervised by a pluggable super-resolution unit. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, PartXV 16, 158–174. Springer.
* Ott, M.; Edunov, S.; Baevski, A.; Fan, A.; Gross, S.; Ng, N.;Grangier, D.; and Auli, M. 2019. fairseq: A Fast, ExtensibleToolkit for Sequence Modeling. In Proceedings of NAACLHLT 2019: Demonstrations.
* Pham, V.; Bluche, T.; Kermorvant, C.; and Louradour, J.2014. Dropout improves recurrent neural networks for handwriting recognition. In 2014 14th international conferenceon frontiers in handwriting recognition, 285–290. IEEE.
* Phan, T. Q.; Shivakumara, P.; Tian, S.; and Tan, C. L.2013. Recognizing text with perspective distortion in natural scenes. In Proceedings of the IEEE International Conference on Computer Vision, 569–576.
* Puigcerver, J. 2017. Are multidimensional recurrent layersreally necessary for handwritten text recognition? In 201714th IAPR International Conference on Document Analysisand Recognition (ICDAR), volume 1, 67–72. IEEE.
* Ramesh, A.; Pavlov, M.; Goh, G.; Gray, S.; Voss, C.; Radford, A.; Chen, M.; and Sutskever, I. 2021. Zero-shot textto-image generation. arXiv preprint arXiv:2102.12092.
* Risnumawan, A.; Shivakumara, P.; Chan, C. S.; and Tan,C. L. 2014. A robust arbitrary text detection system for natural scene images. Expert Systems with Applications.
* Sang, D. V.; and Cuong, L. T. B. 2019. Improving CRNNwith EfficientNet-like feature extractor and multi-head attention for text recognition. In Proceedings of the Tenth International Symposium on Information and CommunicationTechnology, 285–290.
* Sennrich, R.; Haddow, B.; and Birch, A. 2015. Neural machine translation of rare words with subword units. arXivpreprint arXiv:1508.07909.
* Sheng, F.; Chen, Z.; and Xu, B. 2019. NRTR: Ano-recurrence sequence-to-sequence model for scene textrecognition. In 2019 International Conference on DocumentAnalysis and Recognition (ICDAR), 781–786. IEEE.
* Shi, B.; Bai, X.; and Yao, C. 2016. An end-to-end trainableneural network for image-based sequence recognition andits application to scene text recognition. IEEE transactionson pattern analysis and machine intelligence, 39(11): 2298–2304.
* Shi, B.; Wang, X.; Lyu, P.; Yao, C.; and Bai, X. 2016. Robust scene text recognition with automatic rectification. InProceedings of the IEEE conference on computer vision andpattern recognition, 4168–4176.
* Shi, B.; Yang, M.; Wang, X.; Lyu, P.; Yao, C.; and Bai, X.2018. Aster: An attentional scene text recognizer with flexible rectification. IEEE transactions on pattern analysis andmachine intelligence, 41(9): 2035–2048.
* Su, B.; and Lu, S. 2014. Accurate scene text recognitionbased on recurrent neural network. In Asian Conference onComputer Vision, 35–48. Springer.
* Touvron, H.; Cord, M.; Douze, M.; Massa, F.; Sablayrolles,A.; and J´egou, H. 2021. Training data-efficient image transformers & distillation through attention. In InternationalConference on Machine Learning, 10347–10357. PMLR.
* Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,L.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. Attention is all you need. In Advances in neural informationprocessing systems, 5998–6008.
* Voigtlaender, P.; Doetsch, P.; and Ney, H. 2016. Handwriting recognition with large multidimensional long short-termmemory recurrent neural networks. In 2016 15th International Conference on Frontiers in Handwriting Recognition(ICFHR), 228–233. IEEE.
* Wan, Z.; He, M.; Chen, H.; Bai, X.; and Yao, C. 2020.
* Textscanner: Reading characters in order for robust scenetext recognition. In Proceedings of the AAAI Conference onArtificial Intelligence, volume 34, 12120–12127.
* Wang, K.; Babenko, B.; and Belongie, S. 2011. End-to-endscene text recognition. In 2011 International conference oncomputer vision, 1457–1464. IEEE.
* Wang, S.; Wang, Y.; Qin, X.; Zhao, Q.; and Tang, Z. 2019. Scene text recognition via gated cascade attention. In 2019IEEE International Conference on Multimedia and Expo(ICME), 1018–1023. IEEE.
* Wang, T.; Zhu, Y.; Jin, L.; Luo, C.; Chen, X.; Wu, Y.; Wang,Q.; and Cai, M. 2020a. Decoupled Attention Network forText Recognition. In Proceedings of the AAAI Conferenceon Artificial Intelligence.
* Wang, W.; Wei, F.; Dong, L.; Bao, H.; Yang, N.; and Zhou,M. 2020b. Minilm: Deep self-attention distillation for taskagnostic compression of pre-trained transformers. arXivpreprint arXiv:2002.10957.
* Wang, Y.; Xie, H.; Fang, S.; Wang, J.; Zhu, S.; and Zhang,Y. 2021. From Two to One: A New Scene Text RecognizerWith Visual Language Modeling Network. In Proceedingsof the IEEE/CVF International Conference on Computer Vision (ICCV), 14194–14203.
* Wightman, R. 2019. PyTorch Image Models. https://github.com/rwightman/pytorch-image-models.
* Yan, R.; Peng, L.; Xiao, S.; and Yao, G. 2021. Primitive Representation Learning for Scene Text Recognition. In Proceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition (CVPR), 284–293.
* Yu, D.; Li, X.; Zhang, C.; Liu, T.; Han, J.; Liu, J.; and Ding,E. 2020. Towards Accurate Scene Text Recognition WithSemantic Reasoning Networks. In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),12110–12119.
* Yue, X.; Kuang, Z.; Lin, C.; Sun, H.; and Zhang, W. 2020. Robustscanner: Dynamically enhancing positional clues forrobust text recognition. In European Conference on Computer Vision, 135–151. Springer.
* Zhan, F.; and Lu, S. 2019. Esir: End-to-end scene text recognition via iterative image rectification. In Proceedings ofthe IEEE/CVF Conference on Computer Vision and PatternRecognition, 2059–2068.
* Zhang, H.; Yao, Q.; Yang, M.; Xu, Y.; and Bai, X. 2020a.AutoSTR: Efficient backbone search for scene text recognition. In Computer Vision–ECCV 2020: 16th EuropeanConference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXIV 16, 751–767. Springer.
* Zhang, J.; Luo, C.; Jin, L.; Wang, T.; Li, Z.; and Zhou, W.2020b. SaHAN: Scale-aware hierarchical attention networkfor scene text recognition. Pattern Recognition Letters, 136:205–211.